
% VLDB template version of 2020-08-03 enhances the ACM template, version 1.7.0:
% https://www.acm.org/publications/proceedings-template
% The ACM Latex guide provides further information about the ACM template

\documentclass[sigconf, nonacm]{acmart}

%% The following content must be adapted for the final version
% paper-specific
\newcommand\vldbdoi{XX.XX/XXX.XX}
\newcommand\vldbpages{XXX-XXX}
% issue-specific
\newcommand\vldbvolume{14}
\newcommand\vldbissue{1}
\newcommand\vldbyear{2020}
% should be fine as it is
\newcommand\vldbauthors{\authors}
\newcommand\vldbtitle{\shorttitle} 
% leave empty if no availability url should be set
\newcommand\vldbavailabilityurl{https://github.com/vibhash-singh/repr-eng-json_schema_extractor}
% whether page numbers should be shown or not, use 'plain' for review versions, 'empty' for camera ready
\newcommand\vldbpagestyle{plain} 

\begin{document}
\title{RepEng Project: An Approach for Schema Extraction of JSON and Extended JSON Document
Collections}

%%
%% The "author" command and its associated commands are used to define the authors and their affiliations.
\author{Vibhash Kumar Singh}
\affiliation{%
  \institution{Universität Passau}
  \city{Passau}
  \state{Germany}
}
\email{singh13@ads.uni-passau.de}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.

\maketitle

%%% do not modify the following VLDB block %%
%%% VLDB block start %%%
\ifdefempty{\vldbavailabilityurl}{}{
\vspace{.3cm}
\begingroup\small\noindent\raggedright\textbf{Artifact Availability:}\\
The source code, data, and/or other artifacts have been made available at \url{\vldbavailabilityurl}.
\endgroup
}
%%% VLDB block end %%%

\section{Introduction}
In this report, we aim to reproduce the results of Frozza et al.'s \cite{frozza2018approach} approach to JSON schema extraction. We will address the following research question 

\textbf{Research Question}: Is the JSON Schema Discovery method's effectiveness in extracting schemas from JSON documents reproducible within the same dataset?

The original paper \cite{frozza2018approach} introduces JSON Schema Discovery, an approach for extracting schemas from JSON and Extended JSON documents in NoSQL databases. This method enhances data integration and retrieval from schema-less sources, crucial for document-oriented databases. It uniquely enables automatic schema extraction in JSON format, including attributes, data types, and participation constraints. The process involves data summarization and aggregation operations, improving extraction performance \cite{frozza2018approach}. Additionally, this approach is implemented as a free software tool \footnote{https://github.com/feekosta/JSONSchemaDiscovery}, facilitating schema generation, storage, and visualization for MongoDB-stored data collections. We will be using the mentioned tool to reproduce our results. To reproduce the study's findings, we will employ the same tool as mentioned in the original research. This approach ensures consistency in methodology and aids in accurately assessing the reproducibility of the results.

\section{Experimental Evaluation}

In the experiment, the author utilized tracked data from tweets, check-ins, and venues sourced from Foursquare \cite{ccelikten2016modeling}. The original study was conducted on an Amazon EC2 t2.micro instance equipped with an Intel(R) Xeon(R) E5-2676 v3 processor (clocked at 2.40 GHz) and 1GB of RAM \cite{frozza2018approach}. For our reproduction of the experiment, we will be using a machine powered by an Intel Core i7-7700HQ CPU (2.80GHz) with 16 GB of RAM. 

A critical observation made by the author concerns the ordering of raw schema attributes. This was particularly evident in the venues dataset, where the ordering process significantly reduced the number of distinct raw schemata identified—from 257 to 117. This suggests that attribute ordering plays a crucial role in data schema optimization \cite{frozza2018approach}. 

A significant finding in the study is the allocation of processing time. About 99\% of the time is spent on reading documents and generating raw schemas, with only a minimal portion dedicated to actual processing. This highlights the document reading phase as the primary bottleneck in the data processing workflow \cite{frozza2018approach}. Furthermore, the method's efficiency is evident as the increase in the number of JSON documents does not lead to a proportional rise in processing time, indicating its effectiveness in handling larger data sets \cite{frozza2018approach}. The result of the original paper's \cite{frozza2018approach} study is summarized in Table \ref{table:result}.

The criteria for successful confirmation of results include reproducing the experiment with similar data processing and schema extraction efficiency, despite using a different computing setup. Successful reproduction would involve observing a similar reduction in the number of distinct raw schemata due to attribute ordering, as well as confirming that the majority of processing time is consumed in reading documents and generating raw schemas, with actual processing constituting a minimal part. Essentially, reproducing the original study's findings on attribute ordering's impact and processing time allocation, even with varied hardware, would confirm the results.

Given the time elapsed since the original study, challenges in accessing the exact datasets used initially may arise. Modifications, changes, or removal of the datasets are potential issues that could impact the reproduction process. These considerations will be addressed and explored in detail in the future sections of our report.

\begin{table}[h]
\centering
\caption{RESULTS FOR FOURSQUARE DATASETS \cite{frozza2018approach}} 
\scalebox{0.85} {
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Collection} & \textbf{N\_JSON} & \textbf{RS} & \textbf{ROrd} & \textbf{TB}      & \textbf{TT}   & \textbf{TB/TT}        \\ \hline
venues              & 2 million        & 257         & 117            & 7,47 min         & 7,52 min  &99.33\%        \\ \hline 
checkins            & 11 million       & 2           & 2              & 35,27 min        & 35,52 min  &99.29\%      \\ \hline
tweets              & 17 million       & 23          & 16             & 53,11 min        & 53,44 min   &99.38\%     \\ \hline
\end{tabular}
}
\newline
\newline
\newline
N\_JSON-Number of JSON documents, RS - Raw schemas, ROrd - Raw schemas with an ordered structure

TB - Time to obtain the raw schemas, TT - Total time.
\label{table:result}
\end{table}

\bibliographystyle{ACM-Reference-Format}
\bibliography{refrences}

\end{document}
\endinput
